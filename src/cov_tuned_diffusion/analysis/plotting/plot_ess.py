import torch
import matplotlib.pyplot as plt
import numpy as np
import argparse
import os
import pickle

from cov_tuned_diffusion import compute_forward_ess, compute_reverse_ess
from cov_tuned_diffusion.utils.path_config import (
    get_config_path,
    get_model_checkpoint_path,
    get_params_checkpoint_path,
    get_sample_path,
    get_figure_path,
    FIGURES_DIR,
    CHECKPOINTS_DIR,
)


def load_saved_ess_data(args):
    """
    Load ESS data from the pickle files generated by sample_score.py
    """
    results_forward_ess = {cov_form: {n: [] for n in args.num_steps_list} for cov_form in args.cov_forms}
    results_reverse_ess = {cov_form: {n: [] for n in args.num_steps_list} for cov_form in args.cov_forms}
    
    for num_steps in args.num_steps_list:
        for sample_index in args.sample_indices:
            # Process each covariance form
            for cov_form in args.cov_forms:
                # Define file paths according to dataset-specific pattern
                if args.dataset == 'aldp' and cov_form in ['diag', 'full']:
                    # Special case for aldp dataset with diag and full covariance forms
                    forward_pkl_path = os.path.join(args.samples_dir, 'forward', f'{num_steps}steps_{sample_index}sample_aldp_{cov_form}.pkl')
                    backward_pkl_path = os.path.join(args.samples_dir, 'backward', f'{num_steps}steps_{sample_index}sample_aldp_{cov_form}.pkl')
                else:
                    # Standard pattern for other datasets or isotropic covariance
                    forward_pkl_path = os.path.join(args.samples_dir, 'forward', f'{num_steps}steps_{sample_index}sample.pkl')
                    backward_pkl_path = os.path.join(args.samples_dir, 'backward', f'{num_steps}steps_{sample_index}sample.pkl')
                
                if os.path.exists(forward_pkl_path) and os.path.exists(backward_pkl_path):
                    print(f"Loading data for {num_steps} steps, sample index {sample_index}, covariance {cov_form}")
                    
                    # Load forward and backward ESS data
                    with open(forward_pkl_path, 'rb') as f:
                        forward_data = pickle.load(f)
                    
                    with open(backward_pkl_path, 'rb') as f:
                        backward_data = pickle.load(f)
                    
                    # Check if this is the special case for aldp
                    if args.dataset == 'aldp' and cov_form in ['diag', 'full']:
                        # Debug print statements
                        print(f"Keys in forward data for {cov_form}: {list(forward_data.keys())}")
                        print(f"Data type: {type(forward_data)}")
                        
                        # For aldp files with diag/full, try different key structures
                        # try:
                            # # Detailed debugging for diag
                            # if cov_form == 'diag':
                            #     print(f"==== DETAILED DEBUG FOR DIAG at {num_steps} steps ====")
                            #     if isinstance(forward_data, dict):
                            #         for k, v in forward_data.items():
                            #             print(f"Key: {k}, Type: {type(v)}")
                            #             if isinstance(v, dict) and 'log_weights' in v:
                            #                 print(f"Found log_weights in {k} key")
                            #             else:
                            #                 breakpoint()
                                
                        # First try to get data directly if the right format
                        if 'log_weights' in forward_data:
                            all_forward_log_w = torch.cat(forward_data['log_weights'], dim=0)
                            all_backward_log_w = torch.cat(backward_data['log_weights'], dim=0)
                            print(f"Found log_weights directly in data for {cov_form}")
                        # Try to find nested under the covariance form name
                        elif cov_form in forward_data:
                            nested_data_forward = forward_data[cov_form]
                            nested_data_backward = backward_data[cov_form]
                            
                            print(f"Nested keys in forward data: {list(nested_data_forward.keys())}")
                            
                            if 'log_weights' in nested_data_forward:
                                all_forward_log_w = torch.cat(nested_data_forward['log_weights'], dim=0)
                                all_backward_log_w = torch.cat(nested_data_backward['log_weights'], dim=0)
                                print(f"Found log_weights in nested {cov_form} key")
                            elif 'log_w' in nested_data_forward:
                                all_forward_log_w = torch.cat(nested_data_forward['log_w'], dim=0)
                                all_backward_log_w = torch.cat(nested_data_backward['log_w'], dim=0)
                                print(f"Found log_w in nested {cov_form} key")
                            else:
                                print(f"Warning: Could not find log weights in nested data for {num_steps} steps, covariance {cov_form}")
                                continue
                                breakpoint()
                        # Special case for handling files that might have a different structure
                        elif 'diag' in forward_data and cov_form == 'diag':
                            nested_data_forward = forward_data['diag']
                            nested_data_backward = backward_data['diag']
                            
                            print(f"Found diag key for diag covariance form")
                            print(f"Nested keys in diag forward data: {list(nested_data_forward.keys())}")
                            
                            if 'log_weights' in nested_data_forward:
                                all_forward_log_w = torch.cat(nested_data_forward['log_weights'], dim=0)
                                all_backward_log_w = torch.cat(nested_data_backward['log_weights'], dim=0)
                            elif 'log_w' in nested_data_forward:
                                all_forward_log_w = torch.cat(nested_data_forward['log_w'], dim=0)
                                all_backward_log_w = torch.cat(nested_data_backward['log_w'], dim=0)
                            else:
                                print(f"Warning: Could not find log weights in nested diag data")
                                continue
                        # For full covariance, try the 'full' key
                        elif 'full' in forward_data and cov_form == 'full':
                            nested_data_forward = forward_data['full']
                            nested_data_backward = backward_data['full']
                            
                            print(f"Found full key for full covariance form")
                            print(f"Nested keys in full forward data: {list(nested_data_forward.keys())}")
                            
                            if 'log_weights' in nested_data_forward:
                                all_forward_log_w = torch.cat(nested_data_forward['log_weights'], dim=0)
                                all_backward_log_w = torch.cat(nested_data_backward['log_weights'], dim=0)
                            elif 'log_w' in nested_data_forward:
                                all_forward_log_w = torch.cat(nested_data_forward['log_w'], dim=0)
                                all_backward_log_w = torch.cat(nested_data_backward['log_w'], dim=0)
                            else:
                                print(f"Warning: Could not find log weights in nested full data")
                                continue
                        else:
                            print(f"Warning: Could not find appropriate structure for {cov_form} data")
                            # Print all keys to help debug
                            print(f"All available keys: {list(forward_data.keys())}")
                            continue

                    else:
                        # Standard case - need to access by covariance form
                        if cov_form in forward_data and cov_form in backward_data:
                            # Calculate ESS from log weights
                            all_forward_log_w = torch.cat(forward_data[cov_form]['log_weights'], dim=0)
                            all_backward_log_w = torch.cat(backward_data[cov_form]['log_weights'], dim=0)
                        else:
                            print(f"Warning: Covariance form {cov_form} not found in data for {num_steps} steps")
                            continue
                    
                    forward_ess = compute_forward_ess(all_forward_log_w)
                    backward_ess = compute_reverse_ess(all_backward_log_w)
                    
                    total_samples = all_forward_log_w.shape[0]
                    forward_pct = forward_ess.item() / total_samples * 100
                    backward_pct = backward_ess.item() / total_samples * 100

                    print(forward_pct)
                    print(backward_pct)
                    
                    # Store ESS percentages
                    results_forward_ess[cov_form][num_steps].append(forward_pct)
                    results_reverse_ess[cov_form][num_steps].append(backward_pct)
                else:
                    print(f"Warning: Missing data files for {num_steps} steps, sample index {sample_index}, covariance {cov_form}")
                    print(f"Tried to load: {forward_pkl_path}")
    
    # Compute summary statistics
    summary_forward_ess = {}
    for cov_form, by_steps in results_forward_ess.items():
        arrs = by_steps
        median, p25, p75, mean, std = [], [], [], [], []
        valid_steps = []  # Track which steps have valid data
        
        for n in args.num_steps_list:
            a = np.array(arrs[n])
            if len(a) > 0:
                median.append(np.median(a))
                p25.append(np.percentile(a, 25))
                p75.append(np.percentile(a, 75))
                mean.append(np.mean(a))
                std.append(np.std(a))
                valid_steps.append(n)
            else:
                # No data for this step count - don't add any values
                breakpoint()
                print(f"No data for {cov_form} at {n} steps - will not plot this point")
                
        summary_forward_ess[cov_form] = {
            "median": median, "p25": p25, "p75": p75, 
            "mean": mean, "std": std, "valid_steps": valid_steps
        }

    summary_reverse_ess = {}
    for cov_form, by_steps in results_reverse_ess.items():
        arrs = by_steps
        median, p25, p75, mean, std = [], [], [], [], []
        valid_steps = []  # Track which steps have valid data
        
        for n in args.num_steps_list:
            a = np.array(arrs[n])
            if len(a) > 0:
                median.append(np.median(a))
                p25.append(np.percentile(a, 25))
                p75.append(np.percentile(a, 75))
                mean.append(np.mean(a))
                std.append(np.std(a))
                valid_steps.append(n)
            else:
                # No data for this step count - don't add any values
                print(f"No data for {cov_form} at {n} steps - will not plot this point")
                
        summary_reverse_ess[cov_form] = {
            "median": median, "p25": p25, "p75": p75, 
            "mean": mean, "std": std, "valid_steps": valid_steps
        }

    return summary_forward_ess, summary_reverse_ess

def plot_ess(summary_forward_ess, summary_reverse_ess, args):
    """
    Plot both forward and reverse ESS with:
      • one color per cov_form
      • solid lines for forward, dashed for reverse
      • mean and standard deviation error bars
      • clear legend entries
    """
    fig, ax = plt.subplots(figsize=(6, 4))  # Increased figure height to make room for legend

    forward_colors = {
        'ddpm': '#7570b3',  # purple
        'isotropic': '#1f77b4',  # strong blue
        'full':  '#d62728',  # strong red
        'diag': '#2ca02c',  # green
    }

    reverse_colors = {
        'ddpm': '#c2a5cf',  # light purple
        'isotropic': '#76b7b2',  # muted cyan/light blue (pairs w/ blue)
        'full':  '#ff9896',  # pinkish (pairs w/ red)
        'diag': '#98df8a',  # light green (pairs w/ green)
    }

    markers = {'ddpm': 's', 'isotropic': 'o', 'full': '^', 'diag': 'D'}
    labels = {'ddpm': 'DDPM', 'isotropic': 'Ours (Isotropic)', 'full': 'Ours (Full)', 'diag': 'Ours (Diagonal)'}
    linestyles = {'forward': '-', 'reverse': '--'}

    dataset_title = {
        'dw4': 'DW-4',
        'lj13': 'LJ-13',
        'lj55': 'LJ-55',
        'aldp': 'Alanine Dipeptide'
    }

    for i, cov_form in enumerate(args.cov_forms):
        print(f"Plotting {cov_form} ESS")
        marker = markers[cov_form]

        # Forward ESS
        fwd = summary_forward_ess[cov_form]
        valid_steps = fwd["valid_steps"]
        
        if len(valid_steps) > 0:
            y = np.array(fwd["mean"])
            std = np.array(fwd["std"])
            ax.errorbar(
                valid_steps, y,
                yerr=std,
                fmt=marker + linestyles['forward'],
                color=forward_colors[cov_form],
                ecolor=forward_colors[cov_form],
                elinewidth=1.5,
                capsize=5,
                markersize=6,
                label=f"{labels[cov_form]} Forward"
            )

        # Reverse ESS
        rev = summary_reverse_ess[cov_form]
        valid_steps = rev["valid_steps"]
        
        if len(valid_steps) > 0:
            y = np.array(rev["mean"])
            std = np.array(rev["std"])
            ax.errorbar(
                valid_steps, y,
                yerr=std,
                fmt=marker + linestyles['reverse'],
                color=reverse_colors[cov_form],
                ecolor=reverse_colors[cov_form],
                elinewidth=1.5,
                capsize=5,
                markersize=6,
                label=f"{labels[cov_form]} Reverse"
            )

    ax.set_xlabel('Number of Steps', fontsize=18)
    ax.set_ylabel('ESS (%)', fontsize=18)
    ax.set_title(f'ESS (Mean ± Std Dev) for {dataset_title[args.dataset]}', fontsize=18)
    ax.grid(alpha=0.3)
    ax.set_ylim(bottom=0)

    # Customize legend based on dataset
    if args.dataset == 'aldp':
        # For aldp, use a 2-column, 4-row legend arrangement
        ax.legend(fontsize=10, ncol=2, loc='upper center', bbox_to_anchor=(0.5, -0.25), framealpha=0.9)
        plt.subplots_adjust(bottom=0.25)  # More space at bottom for 4-row legend
    else:
        # For other datasets, use the original layout
        ax.legend(fontsize=11, ncol=3, loc='upper center', bbox_to_anchor=(0.5, -0.20), framealpha=0.9)
        plt.subplots_adjust(bottom=0.2)  # Original space for 3-column legend
    
    # Adjust layout to make room for the legend
    plt.tight_layout()

    if args.save_path:
        plt.savefig(args.save_path, bbox_inches='tight', format='pdf', dpi=300)
        print(f"Plot saved to {args.save_path}")
    else:
        plt.show()

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--dataset', type=str, default='dw4')
    parser.add_argument("--net", type=str, default='egnn', help="Network to use.")
    
    # New arguments for sample-based approach
    parser.add_argument('--samples_dir', type=str, 
                        default=str(Path(__file__).parent.parent / 'checkpoints/samples'),
                        help='Directory containing sample files')
    parser.add_argument(
        '--sample_indices', nargs='+', type=int,
        default=[0, 1, 2],
        help="Sample indices to load (from sample_score.py)"
    )
    
    parser.add_argument(
        '--num_steps_list', nargs='+', type=int,
        default=[200, 400, 600],  # Changed default to match your actual data files
        help="List of step counts, e.g. --num_steps_list 200 400 600"
    )
    
    parser.add_argument(
        '--cov_forms', nargs='+', type=str,
        default=['ddpm', 'isotropic', 'full', 'diag'],  # Added 'diag' to defaults
        choices=['ddpm', 'isotropic', 'full', 'diag'],
        help='Covariance form(s) to plot. Can specify multiple options.'
    )

    parser.add_argument('--save_path', type=str, default=None, help='Path to save the plot')
    parser.add_argument('--seed', type=int, default=0, help='Random seed')
    args = parser.parse_args()

    # set the seed
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)

    # Create full samples_dir path for this dataset
    args.samples_dir = os.path.join(args.samples_dir, args.dataset)
    
    if args.save_path is None:
        args.save_path = FIGURES_DIR / 'ess_plot_{args.dataset}_{args.net}.pdf'

    # Load saved ESS data and summary statistics
    print(f"Loading saved ESS data from {args.samples_dir}")
    summary_forward_ess, summary_reverse_ess = load_saved_ess_data(args)

    # Plot results
    print(f"Plotting ESS results")
    plot_ess(summary_forward_ess, summary_reverse_ess, args)

    print(f"Done")

if __name__ == '__main__':
    main()
